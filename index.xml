<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>psc's website</title><link>https://psc-g.github.io/</link><description>Recent content on psc's website</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 20 Jul 2021 08:06:25 +0600</lastBuildDate><atom:link href="https://psc-g.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Episode 5: Repeats &amp; Loops</title><link>https://psc-g.github.io/posts/musicode/episode5/</link><pubDate>Tue, 20 Jul 2021 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/musicode/episode5/</guid><description>The code for this episode is available here.
Loops are such an essential part of programming that I knew I&amp;rsquo;d have to make an episode on them at some point. A natural musical analogue is musical repeats, so the whole episode came fairly naturally!
I thought it&amp;rsquo;d be fun to have some beats to accompany the piano, so I used SuperCollider for that. That proved to be the most challenging part of the episode, as getting the timing right was really hard.</description></item><item><title>MICo: Learning improved representations via sampling-based state similarity for Markov decision processes</title><link>https://psc-g.github.io/posts/research/rl/mico/</link><pubDate>Wed, 16 Jun 2021 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/research/rl/mico/</guid><description>We present a new behavioural distance over the state space of a Markov decision process, and demonstrate the use of this distance as an effective means of shaping the learnt representations of deep reinforcement learning agents.
Pablo Samuel Castro*, Tyler Kastner*, Prakash Panangaden, and Mark Rowland
This blogpost is a summary of our paper. The code is available here.
The following figure gives a nice summary of the empirical gains our new loss provides, yielding an improvement on all of the Dopamine agents.</description></item><item><title>Tips for Reviewing Research Papers</title><link>https://psc-g.github.io/posts/mentoring/reviewing/</link><pubDate>Thu, 10 Jun 2021 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/mentoring/reviewing/</guid><description>The NeurIPS 2021 review period is about to begin, and there will likely be lots of complaining about the quality of reviews when they come out (I&amp;rsquo;m often guilty of this type of complaint).
I decided to write a post describing how I approach paper-reviewing, in the help that it can be useful for others (especially those who are new to reviewing) in writing high quality reviews.
I&amp;rsquo;m mostly an RL researcher, so a lot of the tips below are mostly from my experience reading RL papers.</description></item><item><title>Revisiting Rainbow: Promoting more insightful and inclusive deep reinforcement learning research</title><link>https://psc-g.github.io/posts/research/rl/revisiting_rainbow/</link><pubDate>Mon, 24 May 2021 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/research/rl/revisiting_rainbow/</guid><description>We argue for the value of small- to mid-scale environments in deep RL for increasing scientific insight and help make our community more inclusive.
Johan S. Obando-Ceron and Pablo Samuel Castro
This is a summary of our paper which was accepted at the Thirty-eighth International Conference on Machine Learning (ICML'21). (An initial version was presented at the deep reinforcement learning workshop at NeurIPS 2020).
The code is available here.
You can see the Deep RL talk here.</description></item><item><title>Episode 4: Live Coding &amp; Jazz</title><link>https://psc-g.github.io/posts/musicode/episode4/</link><pubDate>Wed, 28 Apr 2021 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/musicode/episode4/</guid><description>The code for this episode is available here.
I had a different idea for the fourth episode, but then I saw John McLaughlin&amp;rsquo;s tweet about International Jazz day, and decided to do something for that instead.
Obviously I&amp;rsquo;d talk about Jazz in the musical section, but it wasn&amp;rsquo;t clear yet what part of Jazz I&amp;rsquo;d talk about. I spoke to a few people and it seemed like a good idea would be to talk about improvisation, and how jazz musicians do it; in particular, I&amp;rsquo;m hoping this helps people who don&amp;rsquo;t &amp;ldquo;get&amp;rdquo; jazz to understand what we&amp;rsquo;re doing when we play it, and that we&amp;rsquo;re not just playing random notes!</description></item><item><title>Origins of April Fool's Day</title><link>https://psc-g.github.io/posts/misc/origins/</link><pubDate>Thu, 01 Apr 2021 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/misc/origins/</guid><description/></item><item><title>Music during COVID-19</title><link>https://psc-g.github.io/posts/art/covid-music/</link><pubDate>Tue, 16 Mar 2021 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/art/covid-music/</guid><description>It&amp;rsquo;s been just over a year since COVID-19 forced us all to stay home. It&amp;rsquo;s been a terribly difficult year for so many around the globe, and I don&amp;rsquo;t mean this post to minimize the plight of others, but rather simply highlight one of the silver linings in my past year.
One of the things I miss most from pre-COVID days is playing live. I had to cancel a show with my jazz trio when things started getting locked down.</description></item><item><title>Episode 3: Leitmotifs &amp; Variables</title><link>https://psc-g.github.io/posts/musicode/episode3/</link><pubDate>Thu, 11 Mar 2021 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/musicode/episode3/</guid><description>The code for this episode is available here.
I had it in my head that the third episode would talk about variables in the section about Computer Science. Originally I thought the musical would be about chords, but it didn&amp;rsquo;t quite fit well with variables. Then I thought about key signatures, thinking that these are kind of like variables in the sense that you can shift any song into different pitches just by changing key signatures; but again, I wasn&amp;rsquo;t very content with the connection.</description></item><item><title>Episode 2: Bits &amp; Semitones</title><link>https://psc-g.github.io/posts/musicode/episode2/</link><pubDate>Sun, 07 Feb 2021 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/musicode/episode2/</guid><description>The code for this episode is available here.
The idea for doing something with bits seemed kind of natural to me as a second episode. After covering what &amp;ldquo;computation&amp;rdquo; is, why not cover what computers actually &amp;ldquo;see&amp;rdquo; when they run computations?
Given that bits are what makes up everything inside a computer&amp;rsquo;s software, I wanted a musical topic that was inside every type of music (at least in Western music).</description></item><item><title>Metrics and continuity in reinforcement learning</title><link>https://psc-g.github.io/posts/research/rl/metrics_continuity/</link><pubDate>Wed, 03 Feb 2021 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/research/rl/metrics_continuity/</guid><description>In this work we investigate the notion of &amp;ldquo;state similarity&amp;rdquo; in Markov decision processes. This concept is central to generalization in RL with function approximation.
Our paper was published at AAAI'21.
Charline Le Lan, Marc G. Bellemare, and Pablo Samuel Castro
The text below was adapted from Charline&amp;rsquo;s twitter thread
In RL, we often deal with systems with large state spaces. We can’t exactly represent the value of each of these states and need some type of generalization.</description></item><item><title>Episode 1: Musical Notes &amp; Computation</title><link>https://psc-g.github.io/posts/musicode/episode1/</link><pubDate>Thu, 28 Jan 2021 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/musicode/episode1/</guid><description>The code for this episode is available here.
I originally thought this channel would be a kind of educational channel, where people could learn about both music and computer science in a fun and informal way. I tweeted asking for suggestions for what to cover first on the CS side, and Kory Mathewson&amp;rsquo;s response was my favourite.
On the music side, it was kind of a train-of-thought process. The first thing that came to mind when thinking about the first thing you might learn in music theory was musical notes themselves.</description></item><item><title>Introducing MUSICODE</title><link>https://psc-g.github.io/posts/musicode/introducing/</link><pubDate>Sun, 24 Jan 2021 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/musicode/introducing/</guid><description>A musical ode to musical code.
Subscribe to the YouTube channel!.
Each episode will explore a topic in Computer Science, a topic in Music, and combine them in creative ways.
You can find the code I use for each episode here!
The story The reason I decided to start this show was because, thanks to COVID-19, I was no longer performing live with my jazz trio, but I was aching for some type of performative output.</description></item><item><title>Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning</title><link>https://psc-g.github.io/posts/research/rl/pse/</link><pubDate>Thu, 14 Jan 2021 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/research/rl/pse/</guid><description>This paper was accepted as a spotlight at ICLR'21.
We propose a new metric and contrastive loss that comes equipped with theoretical and empirical results.
Policy Similarity Metric We introduce the policy similarity metric (PSM) which is based on bisimulation metrics. In contrast to bisimulation metrics (which is built on reward differences), PSMs are built on differences in optimal policies.
If we were to use this metric for policy transfer (as Doina Precup &amp;amp; I explored previously), we can upper-bound the difference between the optimal and the transferred policy:</description></item><item><title>2020 RL highlights</title><link>https://psc-g.github.io/posts/research/rl/2020highlights/</link><pubDate>Wed, 16 Dec 2020 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/research/rl/2020highlights/</guid><description>As part of TWiML &amp;rsquo;s AI Rewind series, I was asked to provide a list of reinforcement learning papers that were highlights for me in 2020. It&amp;rsquo;s been a difficult year for pretty much everyone, but it&amp;rsquo;s heartening to see that despite all the difficulties, interesting research still came out.
Given the size and breadth of the reinforcement learning research, as well as the fact that I was asked to do this at the end of NeurIPS and right before my vacation, I decided to apply the following rules in the selection:</description></item><item><title>Autonomous navigation of stratospheric balloons using reinforcement learning</title><link>https://psc-g.github.io/posts/research/rl/loon/</link><pubDate>Wed, 02 Dec 2020 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/research/rl/loon/</guid><description>In this work we, quite literally, take reinforcement learning to new heights! Specifically, we use deep reinforcement learning to help control the navigation of stratospheric balloons, whose purpose is to deliver internet to areas with low connectivity. This project is an ongoing collaboration with Loon.
It&amp;rsquo;s been incredibly rewarding to see reinforcement learning deployed successfully in a real setting. It&amp;rsquo;s also been terrific to work alongside such fantastic co-authors:
Marc G.</description></item><item><title>Agence: a dynamic film exploring multi-agent systems and human agency</title><link>https://psc-g.github.io/posts/research/creativity/agence/</link><pubDate>Tue, 01 Dec 2020 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/research/creativity/agence/</guid><description>Agence is a dynamic and interactive film authored by three parties: 1) the director, who establishes the narrative structure and environment, 2) intelligent agents, using reinforcement learning or scripted (hierarchical state machines) AI, and 3) the viewer, who can interact with the system to affect the simulation. We trained RL agents in a multi-agent fashion to control some (or all, based on user choice) of the agents in the film. You can download the game at the Agence website.</description></item><item><title>GANterpretations</title><link>https://psc-g.github.io/posts/research/creativity/ganterpretations/</link><pubDate>Sun, 08 Nov 2020 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/research/creativity/ganterpretations/</guid><description>GANterpretations is an idea I published in this paper, which was accepted to the 4th Workshop on Machine Learning for Creativity and Design at NeurIPS 2020. The code is available here.
At a high level what it does is use the spectrogram of a piece of audio (from a video, for example) to &amp;ldquo;draw&amp;rdquo; a path in the latent space of a BigGAN.
The following video walks through the process:</description></item><item><title>Introduction to reinforcement learning</title><link>https://psc-g.github.io/posts/mentoring/intro-to-rl/</link><pubDate>Wed, 14 Oct 2020 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/mentoring/intro-to-rl/</guid><description>This post is based on this colab.
You can also watch a video where I go through the basics here.
Pueden ver un video (en español) donde presento el material aquí.
Introduction Reinforcement learning methods are used for sequential decision making in uncertain environments. It is typically framed as an agent (the learner) interacting with an environment which provides the agent with reinforcement (positive or negative), based on the agent&amp;rsquo;s decisions.</description></item><item><title>Rigging the Lottery: Making All Tickets Winners</title><link>https://psc-g.github.io/posts/research/other/rigl/rigl/</link><pubDate>Wed, 16 Sep 2020 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/research/other/rigl/rigl/</guid><description>Rigging the Lottery: Making All Tickets Winners is a paper published at ICML 2020 with Utku Evci, Trevor Gale, Jacob Menick, and Erich Elsen, where we introduce an algorithm for training sparse neural networks that uses a fixed parameter count and computational cost throughout training, without sacrificing accuracy relative to existing dense-to-sparse training methods.
You can read more about it in the paper and in our blog post.</description></item><item><title>Artificial General Relativity</title><link>https://psc-g.github.io/posts/misc/agr/</link><pubDate>Wed, 01 Apr 2020 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/misc/agr/</guid><description>We (well, I) introduce a New Field In Science which we (I mean I) call Artificial General Relativity. We (here I really mean &amp;ldquo;we&amp;rdquo;) have all heard of General Relativity and how it revolutionized our understanding of the world around us. Einstein&amp;rsquo;s work, although pivotal, failed in one crucial aspect: although it allowed us to describe gravity and spacetime, it did not allow us to control them. In this paper I (switching to &amp;ldquo;I&amp;rdquo; to avoid sounding pretentious with &amp;ldquo;we&amp;rdquo;) introduce Artificial General Relativity (AGR) which, when achieved, will allow us to control gravity and spacetime.</description></item><item><title>GridWorld Playground</title><link>https://psc-g.github.io/posts/mentoring/gridworldplayground/</link><pubDate>Mon, 16 Mar 2020 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/mentoring/gridworldplayground/</guid><description>GridWorld playground!
I made a website where you can
Draw your own GridWorlds Play around with hyperparameters while agent is training Transfer values between agents &amp;ldquo;Teleport&amp;rdquo; the agent to help it during learning Hope you find it useful and fun!</description></item><item><title>Tips for Interviewing at Google</title><link>https://psc-g.github.io/posts/mentoring/interviewing/</link><pubDate>Mon, 24 Feb 2020 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/mentoring/interviewing/</guid><description>Disclaimer: This post reflects my personal views and not those of my employer.
People often ask me: How do I get a job at Google?
An essential requirement is passing the interviews; unsurprisingly, this is another common question: How do I pass the Google interviews?
While there is no hard and fast rule to pass the Google interviews, I do have some tips and guidelines that have helped others in the past (including myself).</description></item><item><title>Tips for preparing your resume</title><link>https://psc-g.github.io/posts/mentoring/resume/</link><pubDate>Mon, 24 Feb 2020 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/mentoring/resume/</guid><description>Disclaimer: This post reflects my personal views and not those of my employer.
In my previous post providing tips for interviewing at Google, I included the sentence “If you don’t know anyone at Google, you’ve already applied and haven’t heard back in a while, feel free to send me a note with your CV and I’ll see if there’s something I can do.”
I received a number of requests from people who had applied but never heard back.</description></item><item><title>Scalable methods for computing state similarity in deterministic MDPs</title><link>https://psc-g.github.io/posts/research/rl/scalable/</link><pubDate>Fri, 22 Nov 2019 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/research/rl/scalable/</guid><description>This post describes my paper Scalable methods for computing state similarity in deterministic MDPs, published at AAAI 2020. The code is available here.
Motivation We consider distance metrics between states in an MDP. Take the following MDP, where the goal is to reach the green cells:
Physical distance betweent states? Physical distance often fails to capture the similarity properties we&amp;rsquo;d like:
State abstractions Now imagine we add an exact copy of these states to the MDP (think of it as an additional &amp;ldquo;floor&amp;rdquo;):</description></item><item><title>The Cost of Beauty</title><link>https://psc-g.github.io/posts/art/cost-of-beauty/</link><pubDate>Tue, 01 Oct 2019 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/art/cost-of-beauty/</guid><description>In &amp;ldquo;The Evolution of Beauty&amp;rdquo;, Richard O. Prum argues that many of the ornaments present in animals need not have an adaptationist purpose (as is the common held belief), but can be the result of the aesthetic choice of the females.
This web app is inspired by that idea. It creates a set of male and female Things that can mate and reproduce.
Courting Males try to seduce females, and females select the most attractive male.</description></item><item><title>ML-Jam: Performing Structured Improvisations with Pre-trained Models</title><link>https://psc-g.github.io/posts/research/creativity/ml-jam/</link><pubDate>Wed, 19 Jun 2019 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/research/creativity/ml-jam/</guid><description>This paper, published in the International Conference on Computational Creativity, 2019, explores using pre-trained musical generative models in a collaborative setting for improvisation.
You can read more details about it in this blog post.
You can also play with it in this web app!
If you want to play with the code, it is here.
Demos Demo video playing with the web app:
Demo video jamming over Herbie Hancock&amp;rsquo;s Chameleon:</description></item><item><title>Musical Aquarium</title><link>https://psc-g.github.io/posts/art/musical-aquarium/</link><pubDate>Mon, 13 May 2019 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/art/musical-aquarium/</guid><description>I created this website as an experiment to learn p5.js. It creates programmatic &amp;ldquo;music&amp;rdquo; based on the interaction oof the fish you create.
You create fish by clicking anywhere on the screen. The x-axis of the position where you click determines the pitch (taken from the D minor pentatonic scale), while the length of the click determines the size and the speed of the fish.
Whenever the fish bump into each other they &amp;ldquo;sing&amp;rdquo; and move away.</description></item><item><title>Dopamine: A framework for flexible value-based reinforcement learning research</title><link>https://psc-g.github.io/posts/research/rl/dopamine/</link><pubDate>Mon, 27 Aug 2018 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/research/rl/dopamine/</guid><description>Dopamine is a framework for flexible, value-based, reinforcement learning research. It was originally written in TensorFlow, but now all agents have been implemented in JAX.
You can read more about it in our github page and in our white paper.
Original Google AI blogpost.
We have a website where you can easily compare the performance of all the Dopamine agents, which I find really useful:
.
We also provide a set of Colaboratory notebooks that really help understand the framework:</description></item><item><title>JiDiJi: An Experiment in Musical Representation</title><link>https://psc-g.github.io/posts/art/jidiji/</link><pubDate>Sun, 14 Jan 2018 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/art/jidiji/</guid><description>I made this website to convert between music and colours. Read below for details!
About Music can be represented in various forms: as a series of sounds, as a score, as tabs (for guitar), as a series of chord names, as MIDI, as a NoteSequence protocol buffer, and more.
I stumbled upon the Solresol language recently, as well as upon this talk by Adam Neely, and realized that you can also represent music as colours.</description></item><item><title>Family - Over the Years</title><link>https://psc-g.github.io/posts/art/family/</link><pubDate>Sun, 14 May 2006 08:06:25 +0600</pubDate><guid>https://psc-g.github.io/posts/art/family/</guid><description>We photograph ourselves each year on our anniversary.
(This page is not optimized for mobile yet)
Year Michelle Pablo Samuel Sofia Samuel Emilia 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020</description></item></channel></rss>
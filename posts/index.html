<!doctype html><html><head><title>Posts</title>
<meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=stylesheet href=/assets/css/bootstrap.min.css><link rel=stylesheet href=/assets/css/layouts/main.css><link rel=stylesheet href=/assets/css/style.css><link rel=stylesheet href=/assets/css/navigators/navbar.css><link href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css><link rel=icon type=image/png href=/assets/images/psc_emoji.png><link rel=stylesheet href=/assets/css/style.css><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/assets/css/layouts/list.css><link rel=stylesheet href=/assets/css/navigators/sidebar.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span>
</button>
<a class=navbar-brand href=/><img src=/assets/images/psc_emoji.png>psc's website</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"></ul></div></div><img src=/assets/images/psc_emoji.png class=d-none id=main-logo>
<img src=/assets/images/psc_emoji.png class=d-none id=inverted-logo></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><input type=text placeholder=Search data-search id=search-box><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/posts data-filter=all>Posts</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/posts/mentoring/>Mentoring / Education</a><ul><li><a href=/posts/mentoring/cme/>CME is A-OK</a></li><li><a href=/posts/mentoring/gridworldplayground/>GridWorld Playground</a></li><li><a href=/posts/mentoring/introduccion-a-transformers/>Intro a Transformers</a></li><li><a href=/posts/mentoring/intro-to-rl/>Intro to RL</a></li><li><a href=/posts/mentoring/resume/>Preparing your resume</a></li><li><a href=/posts/mentoring/interviewing/>Tips for Interviewing at Google</a></li><li><a href=/posts/mentoring/reviewing/>Tips for Reviewing Research Papers</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/musicode/>MUSICODE</a><ul><li><i class="fas fa-plus-circle"></i><a href=/posts/musicode/phase1/>Phase 1</a><ul><li><a href=/posts/musicode/phase1/introducing/>0-Introducing</a></li><li><a href=/posts/musicode/phase1/episode1/>1-Musical Note & Computation</a></li><li><a href=/posts/musicode/phase1/episode2/>2-Bits & Semitones</a></li><li><a href=/posts/musicode/phase1/episode3/>3-Leitmotifs & Variables</a></li><li><a href=/posts/musicode/phase1/episode4/>4-Live Coding & Jazz</a></li><li><a href=/posts/musicode/phase1/episode5/>5-Repeats & Loops</a></li></ul></li><li><a href=/posts/musicode/introducing/>Introducing</a></li><li><a href=/posts/musicode/ldd/>Losses, Dissonances, and Distortions</a></li><li><a href=/posts/musicode/hallelagine/>Portrait of Hallelagine</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/art/>Art</a><ul><li><a href=/posts/art/albums/>Albums</a></li><li><a href=/posts/art/cost-of-beauty/>Cost of Beauty</a></li><li><a href=/posts/art/covid-music/>Covid Music</a></li><li><a href=/posts/art/family/>Family</a></li><li><a href=/posts/art/jidiji/>JiDiJi</a></li><li><a href=/posts/art/musical-aquarium/>Musical Aquarium</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/misc/>Misc</a><ul><li><a href=/posts/misc/agr/>Artificial General Relativity</a></li><li><a href=/posts/misc/crosswords/>Crosswords</a></li><li><a href=/posts/misc/origins/>Origins of April Fool's Day</a></li><li><a href=/posts/misc/pongday/>PongDay</a></li><li><a href=/posts/misc/yovoy/>yovoy</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/research/>Research</a><ul><li><i class="fas fa-plus-circle"></i><a href=/posts/research/other/>Other</a><ul><li><a href=/posts/research/other/rigl/rigl/>RigL</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/research/rl/>RL</a><ul><li><a href=/posts/research/rl/2020highlights/>2020 RL Highlights</a></li><li><a href=/posts/research/rl/pse/>Contrastive Behavioral Similarity Embeddings</a></li><li><a href=/posts/research/rl/dopamine/>Dopamine</a></li><li><a href=/posts/research/rl/loon/>Flying balloons with RL</a></li><li><a href=/posts/research/rl/from_bbf_to_sss/>From BBF to SSS</a></li><li><a href=/posts/research/rl/atari_defense/>In defense of Atari</a></li><li><a href=/posts/research/rl/metrics_continuity/>Metrics & continuity in RL</a></li><li><a href=/posts/research/rl/mico/>MICo</a></li><li><a href=/posts/research/rl/redo/>ReDo</a></li><li><a href=/posts/research/rl/revisiting_rainbow/>Revisiting Rainbow</a></li><li><a href=/posts/research/rl/scalable/>Scalable methods ...</a></li><li><a href=/posts/research/rl/sparse_rl/>SparseRL</a></li><li><a href=/posts/research/rl/precipice/>Statistical Precipice</a></li><li><a href=/posts/research/rl/tandem/>Tandem RL</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/research/creativity/>Creativity</a><ul><li><a href=/posts/research/creativity/agence/>Agence, a dynamic film</a></li><li><a href=/posts/research/creativity/ganterpretations/>GANterpretations</a></li><li><a href=/posts/research/creativity/ml-jam/>ML-Jam</a></li></ul></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class="content container-fluid" id=content><div class="container-fluid post-card-holder" id=post-card-holder><div class=post-card><a href=/posts/research/rl/atari_defense/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/research/rl/atari_defense/banner.png></div><div class=card-body><h5 class=card-title>In Defense of Atari - the ALE is not 'solved'!</h5><p class="card-text post-summary"><p>This post is based on a talk I gave at the <a href=https://autorlworkshop.github.io/>AutoRL workshop in ICML 2024</a>, which unfortunately was not recorded.</p><h2 id=introduction>Introduction</h2><p>Reinforcement Learning (RL) has been used successfully in a number of challenging tasks, such as <a href=https://deepmind.google/research/breakthroughs/alphago/>beating world champions at Go</a>, <a href=https://www.nature.com/articles/s41586-021-04301-9>controlling tokamak plasmas for nuclear fusion</a>, <a href=https://www.nature.com/articles/s41586-021-03544-w>optimized chip placement</a>, and <a href=https://www.nature.com/articles/s41586-020-2939-8>controlling stratospheric balloons</a>. All these successes have leveraged years of research and expertise and, importantly, rely on the combination of RL algorithms with deep neural networks (as proposed in the seminal <a href=https://www.nature.com/articles/nature14236>DQN paper</a>).</p></p></div><div class=card-footer><span class=float-left>December 2, 2024</span>
<a href=/posts/research/rl/atari_defense/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/research/rl/from_bbf_to_sss/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/research/rl/from_bbf_to_sss/banner.png></div><div class=card-body><h5 class=card-title>From "Bigger, Better, Faster" to "Smaller, Sparser, Stranger"</h5><p class="card-text post-summary"><p>This is a post based on a talk I gave a few times in 2023. I had been meaning to put it in blog post form for over a year but kept putting it off&mldr; I guess better late than never. I think some of the ideas still hold, so hope some of you find it useful!</p><h2 id=bigger-better-faster>Bigger, better, faster</h2><p>In the <a href=https://www.nature.com/articles/nature14236>seminal DQN paper</a>, Mnih et al. demonstrated that reinforcement learning, when combined with neural networks as function approximators, could learn to play Atari 2600 games at superhuman levels. The DQN agent learned to do this over 200 million environment frames, which is roughly equivalent to 1000 hours of human gameplay&mldr;</p></p></div><div class=card-footer><span class=float-left>November 27, 2024</span>
<a href=/posts/research/rl/from_bbf_to_sss/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/research/rl/redo/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/research/rl/redo/overallIQM.png></div><div class=card-body><h5 class=card-title>The Dormant Neuron Phenomenon in Deep Reinforcement Learning</h5><p class="card-text post-summary"><p>We identify the dormant neuron phenomenon in deep reinforcement learning, where an agent&rsquo;s network suffers from an increasing number of inactive neurons, thereby affecting network expressivity.</p><p><em>Ghada Sokar, Rishabh Agarwal, Pablo Samuel Castro*, Utku Evci*</em></p><hr><p>This blogpost is a summary of our <a href=https://arxiv.org/abs/2302.12902>ICML 2023 paper</a>.
The code is available
<a href=https://github.com/google/dopamine/tree/master/dopamine/labs/redo>here</a>.
Many more results and analyses are available in the paper, so I encouraged you to
check it out if interested!</p><p>The following figure gives a nice summary of the overall findings of our work
(we are reporting the Interquantile Mean (IQM) as introduced in
<a href=https://arxiv.org/abs/2108.13264>our Statistical Precipice NeurIPS'21 paper</a>):</p></p></div><div class=card-footer><span class=float-left>June 19, 2023</span>
<a href=/posts/research/rl/redo/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/art/albums/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/art/albums/banner.png></div><div class=card-body><h5 class=card-title>Albums</h5><p class="card-text post-summary"><p>I&rsquo;ve been in bands since I was 12. In a parallel universe I&rsquo;m a full-time musician :D. This page collects the albums I&rsquo;ve released so far, in reverse chronological order. Enjoy!</p><h2 id=the-45s---1-2024>the 45s - #1 (2024)</h2><p>With my good friend Jean-Simon Diallo we started a new project where we release 45s (i.e. singles) consisting of two songs, one written by him and one by me. He does the singing, I do the production and play the instruments. Enjoy!</p></p></div><div class=card-footer><span class=float-left>March 20, 2023</span>
<a href=/posts/art/albums/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/misc/pongday/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/misc/pongday/banner.gif></div><div class=card-body><h5 class=card-title>PongDay</h5><p class="card-text post-summary"><p>I learned on the radio that last November 29th marked the 50th anniversary of the classic arcade game Pong. This game is particularly meaningful for those of us that do RL research, as it is one of the games that is part of the <a href=https://jair.org/index.php/jair/article/view/10819>Arcade Learning Environment</a>, one of the most popular benchmarks. Pong is probably the easiest game of the whole suite, so we often use it as a test to make sure our agents are learning. Learning curves below are for agents trained with the <a href=https://github.com/google/dopamine>Dopamine</a> framework.</p></p></div><div class=card-footer><span class=float-left>December 5, 2022</span>
<a href=/posts/misc/pongday/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/mentoring/introduccion-a-transformers/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/mentoring/introduccion-a-transformers/banner.png></div><div class=card-body><h5 class=card-title>Introducción a los Transformers</h5><p class="card-text post-summary"><p>Como parte de la <a href=https://www.riiaa.org/riiaa5-quito>RIIAA en Quito</a>, di una introducción a los Transformers, que es la arquitectura detrás de avances como GPT-3, Music Transformer, Parti, y muchos otros.</p><h2 id=grabación>Grabación</h2><p>Pueden ver la grabación aquí:</p><center><iframe width=560 height=315 src=https://www.youtube.com/embed/W28CACYxnus title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></center><h2 id=materiales>Materiales</h2><p>Aquí pueden acceder a los diferentes materiales que mencioné durante el curso:</p><ul><li><a href="https://docs.google.com/presentation/d/1nvUn5w1e01bzjFtuaZ50SZb773QEqxgwzlCa-X7XrfY/edit?usp=sharing">Las diapositivas</a> que usé en el curso</li><li><a href=https://transformer.huggingface.co/>Write with Transformers</a> de Hugging Face (GPT-2)</li><li><a href=https://6b.eleuther.ai/>Eleuther GPT-J-6B</a>, que es mucho mejor modelo que el GPT-2 de Hugging Face</li><li>El <a href="https://colab.research.google.com/drive/1psXc1nRmPCY6H7o7bBEY7ZvP68vZSVnN?usp=sharing">colab simple sobre bigrams</a></li><li>El <a href=https://colab.research.google.com/github/google/flax/blob/main/examples/seq2seq/seq2seq.ipynb>colab de Flax sobre LSTMs</a></li><li>El excelente <a href=https://jalammar.github.io/illustrated-transformer/>the Illustrated Transformer</a> de Jay Alammar, en el cual basé la descripción de Transformers.</li><li><a href=http://nlp.seas.harvard.edu/annotated-transformer/>The Annotated Transformer</a></li><li>El <a href=https://parti.research.google/>blog post de Parti</a></li></ul></p></div><div class=card-footer><span class=float-left>October 3, 2022</span>
<a href=/posts/mentoring/introduccion-a-transformers/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/research/rl/sparse_rl/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/research/rl/sparse_rl/banner.gif></div><div class=card-body><h5 class=card-title>Th State of Spars Train ng in D ep Re nforc m nt Le rn ng</h5><p class="card-text post-summary"><p>We perform a systematic investigation into applying a number of existing sparse
training techniques on a variety of deep RL agents and environments, and
conclude by suggesting promising avenues for improving the effectiveness of
sparse training methods, as well as for advancing their use in DRL.</p><p><em>Laura Graesser*, Utku Evci*, Erich Elsen, Pablo Samuel Castro</em></p><hr><p>This blogpost is a summary of our <a href=https://arxiv.org/abs/2206.10369>ICML 2022 paper</a>.
The code is available
<a href=https://github.com/google-research/rigl/tree/master/rigl/rl>here</a>.
Many more results and analyses are available in the paper, so I encouraged you to
check it out if interested!</p></p></div><div class=card-footer><span class=float-left>June 22, 2022</span>
<a href=/posts/research/rl/sparse_rl/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/misc/crosswords/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/misc/crosswords/banner.png></div><div class=card-body><h5 class=card-title>Crosswords: A General Intelligence Challenge?</h5><p class="card-text post-summary"><p>I have become obsessed with crossword puzzles, specifically
<a href=https://www.nytimes.com/crosswords>the NYT crosswords</a>, since
my friend Ralph Crewe gently forced me to start doing them.
Although I&rsquo;m not still at his level, I&rsquo;ve been working on them
daily and getting noticeably better.</p><p>In doing so I&rsquo;ve come to realize they are a fantastic mechanism for testing
generally capable problem-solving, and in this post would like to explain the
various types of challenges they present. I&rsquo;ll be using past NYT crossword
puzzles as examples (they&rsquo;re all at least a week old so should hopefully not be
spoilers for anyone).</p></p></div><div class=card-footer><span class=float-left>April 19, 2022</span>
<a href=/posts/misc/crosswords/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/misc/yovoy/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/misc/yovoy/banner.png></div><div class=card-body><h5 class=card-title>yovoy</h5><p class="card-text post-summary"><h1 id=what-is-a-palindrome>What is a palindrome?</h1><p>A <a href=https://en.wikipedia.org/wiki/Palindrome>palindrome</a> is a phrase that reads
the same way from left to right, and right to left. The rules are that all characters
must be used in both directions, but punctuation, capitalization, and spaces can be
ignored.</p><p>¡Las mismas reglas en español!</p><p>Some well-known Palindromes:</p><blockquote><p>A man, a plan, a canal, Panama!</p></blockquote><blockquote><p>Do geese see god?</p></blockquote><blockquote><p>Yo, banana boy!</p></blockquote><p>Unos palíndromos en español:</p><blockquote><p>Dábale arroz a la zorra el abad.</p></p></div><div class=card-footer><span class=float-left>March 7, 2022</span>
<a href=/posts/misc/yovoy/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/mentoring/cme/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/mentoring/cme/cme.jpg></div><div class=card-body><h5 class=card-title>CME is A-OK</h5><p class="card-text post-summary"><p><a href=https://twitter.com/pcastr/status/1496344364389388289>The thread I wrote</a> at
the start of perf season at Google seemed to resonate with
lots of people, so I decided to put a slightly extended version of it in
blog-post form.</p><img src=/posts/mentoring/cme/thread.png alt="Original Twitter Thread" class=center><h2 id=what-is-perf>What is perf?</h2><p>In brief, &ldquo;perf&rdquo; season at Google is when we evaluate our performance over the
last few months, in the form of a self-assessment, and our peers provide
their assessments on how they perceive our performance. The general
purpose of this exercise is to receive feedback on how to grow as an
engineer/researcher/employee, but it is also the process through which you can
get promoted (by nominating yourself).</p></p></div><div class=card-footer><span class=float-left>February 28, 2022</span>
<a href=/posts/mentoring/cme/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/musicode/hallelagine/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/musicode/hallelagine/banner.png></div><div class=card-body><h5 class=card-title>Portrait of Hallelagine</h5><p class="card-text post-summary"><p>Happy holidays from the MUSICODE &ldquo;team&rdquo;!</p><iframe width=560 height=315 src=https://www.youtube.com/embed/6O3c-j2ySIE title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><p>&ldquo;Portrait of Hallelagine&rdquo;, a mashup of Jaco Pastorius&rsquo; &ldquo;Portrait of Tracy&rdquo;, Leonard Cohen&rsquo;s &ldquo;Hallelujah&rdquo;, and John Lennon&rsquo;s &ldquo;Imagine&rdquo;.</p><p>100% of video editing done with <a href=https://runwayml.com/>Runway</a>!</p></p></div><div class=card-footer><span class=float-left>December 23, 2021</span>
<a href=/posts/musicode/hallelagine/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/research/rl/precipice/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/research/rl/precipice/banner.png></div><div class=card-body><h5 class=card-title>Deep Reinforcement Learning at the Edge of the Statistical Precipice</h5><p class="card-text post-summary"><p>We argue that reliable evaluation in the few run deep RL regime cannot ignore
the uncertainty in results without running the risk of slowing down progress in
the field. We illustrate this point using a case study on the Atari 100k
benchmark, where we find substantial discrepancies between conclusions drawn
from point estimates alone versus a more thorough statistical analysis.
We advocate for reporting interval estimates of aggregate performance and
propose performance profiles to account for the variability in results, as well
as present more robust and efficient aggregate metrics, such as interquartile
mean scores, to achieve small uncertainty in results.</p></p></div><div class=card-footer><span class=float-left>December 6, 2021</span>
<a href=/posts/research/rl/precipice/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div></div><div class=paginator><ul class="pagination pagination-default"><li class="page-item disabled"><a aria-disabled=true aria-label=First class=page-link role=button tabindex=-1><span aria-hidden=true>&#171;&#171;</span></a></li><li class="page-item disabled"><a aria-disabled=true aria-label=Previous class=page-link role=button tabindex=-1><span aria-hidden=true>&#171;</span></a></li><li class="page-item active"><a aria-current=page aria-label="Page 1" class=page-link role=button>1</a></li><li class=page-item><a href=/posts/page/2/ aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/posts/page/3/ aria-label="Page 3" class=page-link role=button>3</a></li><li class=page-item><a href=/posts/page/4/ aria-label="Page 4" class=page-link role=button>4</a></li><li class=page-item><a href=/posts/page/2/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/posts/page/4/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div></section></div><footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=#about>About</a></li><li class=nav-item><a class=smooth-scroll href=#recent-posts>Recent Posts</a></li><li class=nav-item><a class=smooth-scroll href=#publications>Selected Publications</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><span><a href=https://twitter.com/@pcastr target=_blank>Twitter <i class="fab fa-twitter"></i></a></span></li></ul><a rel=me href=https://sigmoid.social/@psc>Mastodon</a></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=#><img src=/assets/images/inverted-logo.png>
Toha</a></div><div class="col-md-4 text-center">© 2020 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/>Powered by
<img src=/assets/images/hugo-logo-wide.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script src=/assets/js/jquery-3.4.1.min.js></script><script src=/assets/js/popper.min.js></script><script src=/assets/js/bootstrap.min.js></script><script src=/assets/js/navbar.js></script><script src=/assets/js/main.js></script><script src=/assets/js/list.js></script></body></html>
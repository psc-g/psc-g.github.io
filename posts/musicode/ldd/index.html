<!doctype html><html><head><title>Losses, Dissonances, and Distortions</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/assets/css/bootstrap.min.css><link rel=stylesheet href=/assets/css/layouts/main.css><link rel=stylesheet href=/assets/css/style.css><link rel=stylesheet href=/assets/css/navigators/navbar.css><link href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css><link rel=icon type=image/png href=/assets/images/psc_emoji.png><link rel=stylesheet href=/assets/css/style.css><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],processEscapes:true,processEnvironments:true},options:{skipHtmlTags:['script','noscript','style','textarea','pre']}};window.addEventListener('load',(event)=>{document.querySelectorAll("mjx-container").forEach(function(x){x.parentElement.classList+='has-jax'})});</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><meta name=description content="Losses, Dissonances, and Distortions"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/assets/css/layouts/single.css><link rel=stylesheet href=/assets/css/navigators/sidebar.css><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-XXXXXXXXX-X','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/><img src=/assets/images/psc_emoji.png>psc's website</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"></ul></div></div><img src=/assets/images/psc_emoji.png class=d-none id=main-logo>
<img src=/assets/images/psc_emoji.png class=d-none id=inverted-logo></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><input type=text placeholder=Search data-search id=search-box><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/posts data-filter=all>Posts</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/posts/mentoring/>Mentoring / Education</a><ul><li><a href=/posts/mentoring/gridworldplayground/>GridWorld Playground</a></li><li><a href=/posts/mentoring/intro-to-rl/>Intro to RL</a></li><li><a href=/posts/mentoring/resume/>Preparing your resume</a></li><li><a href=/posts/mentoring/interviewing/>Tips for Interviewing at Google</a></li><li><a href=/posts/mentoring/reviewing/>Tips for Reviewing Research Papers</a></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/posts/musicode/>MUSICODE</a><ul class=active><li><i class="fas fa-plus-circle"></i><a href=/posts/musicode/phase1/>Phase 1</a><ul><li><a href=/posts/musicode/phase1/introducing/>0-Introducing</a></li><li><a href=/posts/musicode/phase1/episode1/>1-Musical Note & Computation</a></li><li><a href=/posts/musicode/phase1/episode2/>2-Bits & Semitones</a></li><li><a href=/posts/musicode/phase1/episode3/>3-Leitmotifs & Variables</a></li><li><a href=/posts/musicode/phase1/episode4/>4-Live Coding & Jazz</a></li><li><a href=/posts/musicode/phase1/episode5/>5-Repeats & Loops</a></li></ul></li><li><a href=/posts/musicode/introducing/>Introducing</a></li><li><a class=active href=/posts/musicode/ldd/>Losses, Dissonances, and Distortions</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/art/>Art</a><ul><li><a href=/posts/art/cost-of-beauty/>Cost of Beauty</a></li><li><a href=/posts/art/covid-music/>Covid Music</a></li><li><a href=/posts/art/family/>Family</a></li><li><a href=/posts/art/jidiji/>JiDiJi</a></li><li><a href=/posts/art/musical-aquarium/>Musical Aquarium</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/misc/>Misc</a><ul><li><a href=/posts/misc/agr/>Artificial General Relativity</a></li><li><a href=/posts/misc/origins/>Origins of April Fool's Day</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/research/>Research</a><ul><li><i class="fas fa-plus-circle"></i><a href=/posts/research/other/>Other</a><ul><li><a href=/posts/research/other/rigl/rigl/>RigL</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/research/rl/>RL</a><ul><li><a href=/posts/research/rl/2020highlights/>2020 RL Highlights</a></li><li><a href=/posts/research/rl/pse/>Contrastive Behavioral Similarity Embeddings</a></li><li><a href=/posts/research/rl/dopamine/>Dopamine</a></li><li><a href=/posts/research/rl/loon/>Flying balloons with RL</a></li><li><a href=/posts/research/rl/metrics_continuity/>Metrics & continuity in RL</a></li><li><a href=/posts/research/rl/mico/>MICo</a></li><li><a href=/posts/research/rl/revisiting_rainbow/>Revisiting Rainbow</a></li><li><a href=/posts/research/rl/scalable/>Scalable methods ...</a></li><li><a href=/posts/research/rl/tandem/>Tandem RL</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/research/creativity/>Creativity</a><ul><li><a href=/posts/research/creativity/agence/>Agence, a dynamic film</a></li><li><a href=/posts/research/creativity/ganterpretations/>GANterpretations</a></li><li><a href=/posts/research/creativity/ml-jam/>ML-Jam</a></li></ul></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(https://psc-g.github.io/posts/musicode/ldd/banner.gif)></div><div class=page-content><div class="author-profile ml-auto align-self-lg-center"><img class=rounded-circle src=/assets/images/psc_gradient.png><h5 class=author-name>Pablo Samuel Castro</h5><p>September 29, 2021</p></div><div class=title><h1>Losses, Dissonances, and Distortions</h1></div><div class=post-content id=post-content><p>Exploiting the creative possibilities of the numerical signals obtained during
the training of a machine learning model.</p><iframe width=560 height=315 src=https://www.youtube.com/embed/Qjg0bt5hgi4 title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><p>I will be presenting this <a href=https://arxiv.org/abs/2111.05128>paper</a> at the 5th Machine Learning for Creativity and Design Workshop at NeurIPS 2021.</p><p>The code is available <a href=https://github.com/psc-g/musicode/tree/main/ldd>here</a>.</p><h2 id=introduction>Introduction</h2><p>In recent years, there has been a growing interest in using machine learning
models for creative purposes. In most cases, this is with the use of large
<em>generative models</em> which, as their name implies, can generate high-quality
and realistic outputs in <a href=https://magenta.tensorflow.org/music-transformer>music</a>,
<a href=https://compvis.github.io/taming-transformers/>images</a>,
<a href=https://openai.com/blog/gpt-3-apps/>text</a>, and others. The
standard approach for artistic creation using these models is to take a
<em>pre-trained</em> model (or set of models) and use them for producing output.
The artist directs the model&rsquo;s generation by
<a href=/posts/research/creativity/ganterpretations>``navigating'' the latent space</a>,
<a href=https://magenta.tensorflow.org/midi-me>fine-tuning the trained parameters</a>,
or using the model&rsquo;s output to steer another
generative process (e.g.
<a href=https://medium.com/artists-and-machine-intelligence/perception-engines-8a46bc598d57>two</a>
<a href=/posts/research/creativity/ml-jam>examples</a>).</p><p>At a high-level what all these approaches are doing is converting the numerical
signal of a machine learning model&rsquo;s output into art, whether implicitly or
explicitly. However, in most (if not all) cases they only do so
<em>after the initial model has been trained</em>. This is somewhat unfortunate, as there
are plenty of numerical signals available <em>during the training process</em>,
such as the loss and gradient values, that can be used for creative purposes.</p><p>In this work I study using the losses and gradients obtained
during the training of a simple function approximator as a mechanism for
creating musical dissonance and visual distortion in a solo piano performance
setting. These dissonances and distortions become part of an artistic
performance not just by affecting the visualizations, but also by affecting the
artistic musical performance. The system is designed such that the performer
can in turn affect the training process itself, thereby creating a closed
feedback loop between two processes: the training of a machine learning model
and the performance of an improvised piano piece.</p><h2 id=components>Components</h2><h3 id=losses-and-gradients>Losses and gradients</h3><p>Let $f_\theta:X\rightarrow Y$ denote a function parameterized by a
$d$-dimensional vector of weights $\theta\in\mathbb{R}^d$ that aims to
approximate a &ldquo;true&rdquo; function $f:X\rightarrow Y$. We improve the
approximation by updating the parameters $\theta$ so as to minimize a loss
function $\mathcal{L}(f_\theta, f)\rightarrow\mathbb{R}$. This is typically
done using gradient descent, where we use the derivative (or gradient) of the
loss function to update the parameters:
$\theta \leftarrow \theta - \alpha \nabla \mathcal{L}(f_\theta, f)$,
where $\alpha$ is a learning rate. If set properly, this process will
result in $\mathcal{L}\rightarrow 0$.</p><p><a title="Pasafr, CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0>, via Wikimedia Commons" href=https://commons.wikimedia.org/wiki/File:Gradient_method.svg><img width=512 alt="Gradient method" src=https://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Gradient_method.svg/512px-Gradient_method.svg.png align=center></a></p><p>Thus, at every iteration of the learning process we have $d+1$ values
at our disposal: the $d$ partial gradients from $\nabla\mathcal{L}$
and the loss itself. In the next sections I will describe how I use these
values as part of a performance, but of course there are an infinitude of
ways that artists can incorporate these as part of their work.</p><h3 id=cubics>Cubics</h3><p>In order for the learning dynamics to be clearly observed during the
performance, it is preferable that the learning process is able to converge
relatively quickly. For this reason I chose two relatively simple functions to
learn: Cubic polynomials and Lissajous knots.</p><p>The polynomials are single-valued functions $f_{a,b,c,d}:\mathbb{R}\rightarrow\mathbb{R}$:</p><p>$$f_{{\bf a,b,c,d}}(x) = ax^3 + bx^2 + cx + d$$</p><p>The parameters $\theta$ of the learned function aim to approach
the true values of $a$, $b$, $c$, and $d$. We use the mean-squared error loss:</p><p>$$ \mathbb{E}_x\left[\sqrt{\left(f_{a,b,c,d}(x) - f_{\theta}(x)\right)^2}\right] $$</p><p>You can play with the following widget to see learning cubics in action:</p><code>a: <input id=aVal placeholder=1.2 value=1.2 onchange=generatePlot() type=number>
b: <input id=bVal placeholder=1.2 value=1.2 onchange=generatePlot() type=number>
c: <input id=cVal placeholder=1.2 value=1.2 onchange=generatePlot() type=number>
d: <input id=dVal placeholder=1.2 value=1.2 onchange=generatePlot() type=number><p>numPoints: <input id=points placeholder=100 value=100 type=number>
iterations: <input id=iterations placeholder=100 value=100 type=number>
<button onclick=init()>Regenerate</button>
<button onclick=doLearning()>Learn!</button></code></p><div id=graph></div><script>window.PlotlyConfig={MathJaxConfig:'local'}</script><script src=https://cdn.plot.ly/plotly-latest.min.js></script><script src=https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.12.5></script><script src=/posts/musicode/ldd/script.js></script><h3 id=lissajous-knots>Lissajous knots</h3><p>Lissajous knots are multi-valued functions
$g_{n_x,n_y,n_z,a,b,c}:\mathbb{R}\rightarrow\mathbb{R}^3$, where $n_x$, $n_y$,
and $n_z$ are integers:</p><p>$$g_{n_x,n_y,n_z,{\bf a,b,c}}(t) = \langle cos(n_x t + a), cos(n_y t + b), cos(n_z t + c) \rangle $$</p><p><a title="Jim.belk Animation: MichaelFrey, Public domain, via Wikimedia Commons" href=https://commons.wikimedia.org/wiki/File:Lissajous_8_21_Knot_Animated.gif><img width=256 alt="Lissajous 8 21 Knot Animated" src=https://upload.wikimedia.org/wikipedia/commons/1/15/Lissajous_8_21_Knot_Animated.gif align=center></a></p><p>The parameters $\theta$ of the learned function aim to approach
the true values of $a$, $b$, and $c$ (e.g. the integer-parameters are not learned).
We again use the mean-squared error loss:</p><p>$$\mathbb{E}_t\left[\sqrt{\left(g_{n_x,n_y,n_z,a,b,c}(t) - g_\theta\right(t))^2}\right]$$</p><h3 id=dissonances>Dissonances</h3><p>Music is made of the combination of individual {\em notes} played on a variety
of instruments. Each note is actually a combination of a number of pitches or
frequencies: the {\em fundamental frequency}\footnote{This is typically what
is referred to as &ldquo;the pitch&rdquo; of a played note.}; and a series of {\em overtone
frequencies}, that are pitches at higher frequencies than the fundamental.
A well-tuned instrument will have overtones that are {\em multiples} of the
fundamental frequency (and in this case, these are called harmonics). For
example, a well-tuned A note may have the following frequencies (one
fundamental and three overtones): $\lbrace 440, 880, 1320, 1760 \rbrace$.
If we detune the overtones by an amount proportional to the loss:
$\lbrace 440, 880 (1 + \mathcal{L}), 1320 (1 + \mathcal{L}), 1760 (1 + \mathcal{L}) \rbrace$, then what
we will hear throughout the learning process is the sound &ldquo;converging&rdquo;
to its well-tuned state, starting from a detuned state
(play with an example <a href=https://sound-of-learning.glitch.me/>here</a>.</p><h3 id=distortions>Distortions</h3><p>In addition to creating dissonance, we can create visual distortions using the
partial gradients of $\nabla\mathcal{L}$, and two instances of this are explored:</p><p><strong>1)</strong> The video input is split into its RGB components and each is
translated by an amount proportional to the first three partial gradients
of $\nabla\mathcal{L}$. Thus, when fully converged, each of these gradients will be
zero, and each of the three RGB frames will be exactly superimposed, resulting
in an unaltered image.</p><p><strong>2)</strong> The previous distortion distorted the placement of the
RGB components but kept the aspect ratios of each unaltered. In this distortion
the RGB components are unaltered, but the $(x,y)$ positions of
each pixel are distorted by an amount proportional to $(cos(\nabla\mathcal{L}_1), cos(\nabla\mathcal{L}_2))$,
where $\nabla\mathcal{L}_i$ denotes the $i$-th partial derivative of $\nabla\mathcal{L}$.</p><h2 id=performance>Performance</h2><p>The above ideas are combined into a musical performance, played on a Disklavier
piano, which is a regular acoustic piano that can also send MIDI signal to the
computer. The performance is organized into 4 parts:</p><p><strong>Part 1:</strong> Every time a bass note is played, a new polynomial is generated
by sampling the coefficients $a,b,c,d$, and a new approximant is generated by sampling
$\theta$. Every note played on the upper half of the piano induces a gradient step, and
the loss of each step is used to detune the played note&rsquo;s overtones. The target and
learned polynomials are displayed on a black background.</p><img src=/posts/musicode/ldd/part1.png alt="Part 1" width=50% class=center><p><strong>Part 2:</strong> Every time a chord is played on the left hand, a new target Lissajous
knot is generated by samplinig $n_x,n_y,n_z,a,b,c$, and a new approximant is generated
by sampling $\theta$. Gradient steps are continuously performed as long as the chord
is held, with the loss detuning the overtones of the notes being played.</p><img src=/posts/musicode/ldd/part2.png alt="Part 2" width=50% class=center><p><strong>Part 3:</strong> Same as part 2, but we also display a video of the performer in the
background and use Distortion (1) to affect the RGB channels.</p><img src=/posts/musicode/ldd/part3.png alt="Part 3" width=50% class=center><p><strong>Part 4:</strong> Same as part 1, but with a video of the performer in the
background. Additionally, each note played triggers a &ldquo;bubble&rdquo; superimposed on the video
which is distorted using Distortion (2).</p><img src=/posts/musicode/ldd/part4.png alt="Part 4" width=50% class=center><p>This is meant to be an improvised &ldquo;process piece&rdquo; that is different evey time
it is performed.</p></div><div class=btn-improve-page><a href=https://github.com/psc-g/psc-g.github.io/edit/master/content/posts/musicode/ldd.md><i class="fas fa-code-branch"></i>Improve this page</a></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/posts/research/rl/mico/ class="btn btn-outline-info"><span><i class="fas fa-chevron-circle-left"></i>Prev</span><br><span>MICo: Learning improved representations via sampling-based state similarity for Markov decision processes</span></a></div><div class="col-md-6 next-article"><a href=/posts/musicode/introducing/ class="btn btn-outline-info"><span>Next <i class="fas fa-chevron-circle-right"></i></span><br><span>Introducing MUSICODE Phase 2</span></a></div></div><hr><div id=disqus_thread></div><script type=text/javascript>(function(){if(window.location.hostname=="localhost")return;var dsq=document.createElement("script");dsq.type="text/javascript";dsq.async=true;var disqus_shortname="does-not-exist";dsq.src="//"+disqus_shortname+".disqus.com/embed.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(dsq);})();</script><noscript>Please enable JavaScript to view the
<a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com/ class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div></div></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center pl-3">Table of Contents</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#components>Components</a><ul><li><a href=#losses-and-gradients>Losses and gradients</a></li><li><a href=#cubics>Cubics</a></li><li><a href=#lissajous-knots>Lissajous knots</a></li><li><a href=#dissonances>Dissonances</a></li><li><a href=#distortions>Distortions</a></li></ul></li><li><a href=#performance>Performance</a></li></ul></nav></div></div></section></div><footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=#about>About</a></li><li class=nav-item><a class=smooth-scroll href=#recent-posts>Recent Posts</a></li><li class=nav-item><a class=smooth-scroll href=#publications>Publications</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><span><a href=https://twitter.com/@pcastr target=_blank>Twitter <i class="fab fa-twitter"></i></a></span></li></ul></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=#><img src=/assets/images/inverted-logo.png>
Toha</a></div><div class="col-md-4 text-center">© 2020 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/>Powered by
<img src=/assets/images/hugo-logo-wide.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script src=/assets/js/jquery-3.4.1.min.js></script><script src=/assets/js/popper.min.js></script><script src=/assets/js/bootstrap.min.js></script><script src=/assets/js/navbar.js></script><script src=/assets/js/main.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script><script src=/assets/js/single.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>
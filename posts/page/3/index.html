<!doctype html><html><head><title>Posts</title>
<meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=stylesheet href=/assets/css/bootstrap.min.css><link rel=stylesheet href=/assets/css/layouts/main.css><link rel=stylesheet href=/assets/css/style.css><link rel=stylesheet href=/assets/css/navigators/navbar.css><link href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css><link rel=icon type=image/png href=/assets/images/psc_emoji.png><link rel=stylesheet href=/assets/css/style.css><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/assets/css/layouts/list.css><link rel=stylesheet href=/assets/css/navigators/sidebar.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span>
</button>
<a class=navbar-brand href=/><img src=/assets/images/psc_emoji.png>psc's website</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"></ul></div></div><img src=/assets/images/psc_emoji.png class=d-none id=main-logo>
<img src=/assets/images/psc_emoji.png class=d-none id=inverted-logo></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><input type=text placeholder=Search data-search id=search-box><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/posts data-filter=all>Posts</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/posts/mentoring/>Mentoring / Education</a><ul><li><a href=/posts/mentoring/cme/>CME is A-OK</a></li><li><a href=/posts/mentoring/gridworldplayground/>GridWorld Playground</a></li><li><a href=/posts/mentoring/introduccion-a-transformers/>Intro a Transformers</a></li><li><a href=/posts/mentoring/intro-to-rl/>Intro to RL</a></li><li><a href=/posts/mentoring/resume/>Preparing your resume</a></li><li><a href=/posts/mentoring/interviewing/>Tips for Interviewing at Google</a></li><li><a href=/posts/mentoring/reviewing/>Tips for Reviewing Research Papers</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/musicode/>MUSICODE</a><ul><li><i class="fas fa-plus-circle"></i><a href=/posts/musicode/phase1/>Phase 1</a><ul><li><a href=/posts/musicode/phase1/introducing/>0-Introducing</a></li><li><a href=/posts/musicode/phase1/episode1/>1-Musical Note & Computation</a></li><li><a href=/posts/musicode/phase1/episode2/>2-Bits & Semitones</a></li><li><a href=/posts/musicode/phase1/episode3/>3-Leitmotifs & Variables</a></li><li><a href=/posts/musicode/phase1/episode4/>4-Live Coding & Jazz</a></li><li><a href=/posts/musicode/phase1/episode5/>5-Repeats & Loops</a></li></ul></li><li><a href=/posts/musicode/introducing/>Introducing</a></li><li><a href=/posts/musicode/ldd/>Losses, Dissonances, and Distortions</a></li><li><a href=/posts/musicode/hallelagine/>Portrait of Hallelagine</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/art/>Art</a><ul><li><a href=/posts/art/albums/>Albums</a></li><li><a href=/posts/art/cost-of-beauty/>Cost of Beauty</a></li><li><a href=/posts/art/covid-music/>Covid Music</a></li><li><a href=/posts/art/family/>Family</a></li><li><a href=/posts/art/jidiji/>JiDiJi</a></li><li><a href=/posts/art/musical-aquarium/>Musical Aquarium</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/misc/>Misc</a><ul><li><a href=/posts/misc/agr/>Artificial General Relativity</a></li><li><a href=/posts/misc/crosswords/>Crosswords</a></li><li><a href=/posts/misc/origins/>Origins of April Fool's Day</a></li><li><a href=/posts/misc/pongday/>PongDay</a></li><li><a href=/posts/misc/yovoy/>yovoy</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/research/>Research</a><ul><li><i class="fas fa-plus-circle"></i><a href=/posts/research/other/>Other</a><ul><li><a href=/posts/research/other/rigl/rigl/>RigL</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/research/rl/>RL</a><ul><li><a href=/posts/research/rl/2020highlights/>2020 RL Highlights</a></li><li><a href=/posts/research/rl/pse/>Contrastive Behavioral Similarity Embeddings</a></li><li><a href=/posts/research/rl/dopamine/>Dopamine</a></li><li><a href=/posts/research/rl/loon/>Flying balloons with RL</a></li><li><a href=/posts/research/rl/from_bbf_to_sss/>From BBF to SSS</a></li><li><a href=/posts/research/rl/atari_defense/>In defense of Atari</a></li><li><a href=/posts/research/rl/metrics_continuity/>Metrics & continuity in RL</a></li><li><a href=/posts/research/rl/mico/>MICo</a></li><li><a href=/posts/research/rl/redo/>ReDo</a></li><li><a href=/posts/research/rl/revisiting_rainbow/>Revisiting Rainbow</a></li><li><a href=/posts/research/rl/scalable/>Scalable methods ...</a></li><li><a href=/posts/research/rl/sparse_rl/>SparseRL</a></li><li><a href=/posts/research/rl/precipice/>Statistical Precipice</a></li><li><a href=/posts/research/rl/tandem/>Tandem RL</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/research/creativity/>Creativity</a><ul><li><a href=/posts/research/creativity/agence/>Agence, a dynamic film</a></li><li><a href=/posts/research/creativity/ganterpretations/>GANterpretations</a></li><li><a href=/posts/research/creativity/ml-jam/>ML-Jam</a></li></ul></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class="content container-fluid" id=content><div class="container-fluid post-card-holder" id=post-card-holder><div class=post-card><a href=/posts/research/rl/metrics_continuity/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/research/rl/metrics_continuity/banner.png></div><div class=card-body><h5 class=card-title>Metrics and continuity in reinforcement learning</h5><p class="card-text post-summary"><p>In this work we investigate the notion of &ldquo;state similarity&rdquo; in Markov decision processes. This concept is central to generalization in RL with function approximation.</p><p><a href=https://arxiv.org/abs/2102.01514>Our paper</a> was published at AAAI'21.</p><p><em>Charline Le Lan, Marc G. Bellemare, and Pablo Samuel Castro</em></p><p>The text below was adapted from <a href=https://twitter.com/charlinelelan/status/1357006401952972808>Charline&rsquo;s twitter thread</a></p><p>In RL, we often deal with systems with large state spaces. We can’t exactly represent the value of each of these states and need some type of generalization. One way to do that is to look at structured representations in which similar states are assigned similar predictions.</p></p></div><div class=card-footer><span class=float-left>February 3, 2021</span>
<a href=/posts/research/rl/metrics_continuity/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/musicode/phase1/episode1/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/musicode/phase1/episode1/banner.gif></div><div class=card-body><h5 class=card-title>Episode 1: Musical Notes & Computation</h5><p class="card-text post-summary"><iframe width=560 height=315 src=https://www.youtube.com/embed/BrxO-Lssnjg frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><p>The code for this episode is available <a href=https://github.com/psc-g/musicode/tree/main/ep1>here</a>.</p><p>I originally thought this channel would be a kind of educational channel, where people could learn about both music and computer science in a fun and informal way. <a href=https://twitter.com/pcastr/status/1296122430977716224>I tweeted asking for suggestions for what to cover first on the CS side</a>, and <a href=https://twitter.com/korymath/status/1296122717318590465>Kory Mathewson&rsquo;s response</a> was my favourite.</p><p>On the music side, it was kind of a train-of-thought process. The first thing that came to mind when thinking about the first thing you might learn in music theory was musical notes themselves.</p></p></div><div class=card-footer><span class=float-left>January 28, 2021</span>
<a href=/posts/musicode/phase1/episode1/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/musicode/phase1/introducing/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/musicode/phase1/introducing/banner.png></div><div class=card-body><h5 class=card-title>Introducing MUSICODE</h5><p class="card-text post-summary"><iframe width=560 height=315 src=https://www.youtube.com/embed/jmoFkx0iGB4 frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><p>A musical ode to musical code.</p><p><a href=https://www.youtube.com/channel/UCrZNf0XkxtXE0tsy1y2RT0w>Subscribe to the YouTube channel!</a>.</p><p>Each episode will explore a topic in Computer Science, a topic in Music, and combine them in creative ways.</p><p>You can find the code I use for each episode <a href=https://github.com/psc-g/musicode>here</a>!</p><h2 id=the-story>The story</h2><p>The reason I decided to start this show was because, thanks to COVID-19, I was no longer performing live with my <a href=https://www.psctrio.com/>jazz trio</a>, but I was aching for some type of performative output. I had recently bought a <a href=https://en.wikipedia.org/wiki/Disklavier>disklavier</a>, which had been a dream of mine for quite some time, especially after seeing <a href="https://dantepfer.com/blog/?p=711">Dan Tepfer&rsquo;s Natural Machines</a>.</p></p></div><div class=card-footer><span class=float-left>January 24, 2021</span>
<a href=/posts/musicode/phase1/introducing/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/research/rl/pse/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/research/rl/pse/pse.png></div><div class=card-body><h5 class=card-title>Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning</h5><p class="card-text post-summary"><p>This <a href=https://arxiv.org/abs/2101.05265>paper</a> was accepted as a spotlight at ICLR'21.</p><p>We propose a new metric and contrastive loss that comes equipped with theoretical and empirical results.</p><img src=/posts/research/rl/pse/jumpy.png alt="Jumping task" width=50% class=center><h2 id=policy-similarity-metric>Policy Similarity Metric</h2><p>We introduce the policy similarity metric (PSM) which is based on <a href=https://arxiv.org/abs/1207.4114>bisimulation metrics</a>.
In contrast to bisimulation metrics (which is built on reward differences), PSMs are built on differences in optimal policies.</p><img src=/posts/research/rl/pse/psm.png alt="Policy similarity metric" width=80% class=center><p>If we were to use this metric for policy transfer (as Doina Precup & I <a href=http://ojs.aaai.org/index.php/AAAI/article/view/7751>explored previously</a>), we can upper-bound the difference between the optimal and the transferred policy:</p></p></div><div class=card-footer><span class=float-left>January 14, 2021</span>
<a href=/posts/research/rl/pse/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/research/rl/2020highlights/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/research/rl/2020highlights/banner.png></div><div class=card-body><h5 class=card-title>2020 RL highlights</h5><p class="card-text post-summary"><p>As part of <a href=https://twimlai.com/>TWiML</a> &rsquo;s AI Rewind series, I was asked to provide a list of reinforcement learning papers that were highlights for me in 2020. It&rsquo;s been a difficult year for pretty much everyone, but it&rsquo;s heartening to see that despite all the difficulties, interesting research still came out.</p><p>Given the size and breadth of the reinforcement learning research, as well as the fact that I was asked to do this at the end of NeurIPS and right before my vacation, I decided to apply the following rules in the selection:</p></p></div><div class=card-footer><span class=float-left>December 16, 2020</span>
<a href=/posts/research/rl/2020highlights/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/research/rl/loon/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/research/rl/loon/loonAnimation.gif></div><div class=card-body><h5 class=card-title>Autonomous navigation of stratospheric balloons using reinforcement learning</h5><p class="card-text post-summary"><p>In this work we, quite literally, take reinforcement learning to new heights! Specifically, we use deep reinforcement learning to help control the navigation of stratospheric balloons, whose purpose is to deliver internet to areas with low connectivity. This project is an ongoing collaboration with <a href=https://loon.com/>Loon</a>.</p><p>It&rsquo;s been incredibly rewarding to see reinforcement learning deployed successfully in a real setting. It&rsquo;s also been terrific to work alongside such fantastic co-authors:<br><em>Marc G. Bellemare, Salvatore Candido, Pablo Samuel Castro, Jun Gong, Marlos C. Machado, Subhodeep Moitra, Sameera S. Ponda, Ziyu Wang</em></p></p></div><div class=card-footer><span class=float-left>December 2, 2020</span>
<a href=/posts/research/rl/loon/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/research/creativity/agence/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/research/creativity/agence/banner.png></div><div class=card-body><h5 class=card-title>Agence: a dynamic film exploring multi-agent systems and human agency</h5><p class="card-text post-summary"><p>Agence is a dynamic and interactive film authored by three parties: 1) the
director, who establishes the narrative structure and environment, 2)
intelligent agents, using reinforcement learning or scripted (hierarchical
state machines) AI, and 3) the viewer, who can interact with the system to
affect the simulation. We trained RL agents in a multi-agent fashion to control
some (or all, based on user choice) of the agents in the film. You can download
the game at <a href=https://www.agence.ai/>the Agence website</a>.</p></p></div><div class=card-footer><span class=float-left>December 1, 2020</span>
<a href=/posts/research/creativity/agence/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/research/creativity/ganterpretations/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/research/creativity/ganterpretations/gandy.gif></div><div class=card-body><h5 class=card-title>GANterpretations</h5><p class="card-text post-summary"><p>GANterpretations is an idea I published in <a href=https://arxiv.org/abs/2011.05158>this paper</a>, which was accepted to the <a href=https://neurips2020creativity.github.io/>4th Workshop on Machine Learning for Creativity and Design at NeurIPS 2020</a>. The code is available <a href=https://github.com/psc-g/ganterpretation>here</a>.</p><p>At a high level what it does is use the spectrogram of a piece of audio (from a video, for example) to &ldquo;draw&rdquo; a path in the latent space of a BigGAN.</p><p>The following video walks through the process:</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/j2J8_Q9ZNa8?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div><h2 id=gans>GANs</h2><p><a href=https://en.wikipedia.org/wiki/Generative_adversarial_network>GANs</a> are generative models trained to reproduce images from a given dataset. The way GANs work is they are trained to learn a <em>latent space</em> $ Z\in\mathbb{R}^d $, where each point $ z\in Z $ generates a unique image $ G(z) $, where $ G $ is the <em>generator</em> of the GAN. When trained properly, these latent spaces are learned in a structured manner, where nearby points generate similar images.</p></p></div><div class=card-footer><span class=float-left>November 8, 2020</span>
<a href=/posts/research/creativity/ganterpretations/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/mentoring/intro-to-rl/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/mentoring/intro-to-rl/cartpole.gif></div><div class=card-body><h5 class=card-title>Introduction to reinforcement learning</h5><p class="card-text post-summary"><p>This post is based on <a href="https://colab.research.google.com/github/psc-g/intro_to_rl/blob/master/Introduction_to_reinforcement_learning.ipynb#scrollTo=XVrlWe2YPpXt">this colab</a>.</p><p>You can also watch a video where I go through the basics <a href=https://youtu.be/xMZE-9WECQE>here</a>.</p><p>Pueden ver un video (en español) donde presento el material <a href=https://youtu.be/ZOaA4svJH3U>aquí</a>.</p><h2 id=introduction>Introduction</h2><p>Reinforcement learning methods are used for sequential decision making in uncertain environments. It is typically framed as an agent (the learner) interacting with an environment which provides the agent with reinforcement (positive or negative), based on the agent&rsquo;s decisions. The agent leverages this reinforcement to update its behaviour in an aim to get closer to acting optimally. In interacting with the uncertain environment, the agent is also learning about the dynamics of the underlying system.</p></p></div><div class=card-footer><span class=float-left>October 14, 2020</span>
<a href=/posts/mentoring/intro-to-rl/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/research/other/rigl/rigl/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/research/other/rigl/rigl.gif></div><div class=card-body><h5 class=card-title>Rigging the Lottery: Making All Tickets Winners</h5><p class="card-text post-summary"><p><a href=https://proceedings.icml.cc/static/paper_files/icml/2020/287-Paper.pdf>Rigging the Lottery: Making All Tickets Winners</a> is a paper published at <a href=https://icml.cc/Conferences/2020>ICML 2020</a> with Utku Evci, Trevor Gale, Jacob Menick, and Erich Elsen, where we introduce an algorithm for training sparse neural networks that uses a fixed parameter count and computational cost throughout training, without sacrificing accuracy relative to existing dense-to-sparse training methods.</p><p>You can read more about it in the paper and in our <a href=https://ai.googleblog.com/2020/09/improving-sparse-training-with-rigl.html>blog post</a>.</p><img src=/posts/research/other/rigl/rigl.gif alt=RigL width=25% class=center></p></div><div class=card-footer><span class=float-left>September 16, 2020</span>
<a href=/posts/research/other/rigl/rigl/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/misc/agr/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/misc/agr/cafe.png></div><div class=card-body><h5 class=card-title>Artificial General Relativity</h5><p class="card-text post-summary"><p>We (well, I) introduce a New Field In Science which we (I mean I) call Artificial General Relativity. We
(here I really mean &ldquo;we&rdquo;) have all heard of General Relativity and how it revolutionized our understanding of
the world around us. Einstein&rsquo;s work, although pivotal, failed in one crucial aspect: although it allowed us to
describe gravity and spacetime, it did not allow us to control them. In this paper I (switching to &ldquo;I&rdquo; to avoid
sounding pretentious with &ldquo;we&rdquo;) introduce Artificial General Relativity (AGR) which, when achieved, will
allow us to control gravity and spacetime. I present a set of practical approaches to achieve AGR which serve
as reasonable baselines for future work.</p></p></div><div class=card-footer><span class=float-left>April 1, 2020</span>
<a href=/posts/misc/agr/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/mentoring/gridworldplayground/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/mentoring/gridworldPlayground/gridWorldPlaygroundBanner.gif></div><div class=card-body><h5 class=card-title>GridWorld Playground</h5><p class="card-text post-summary"><p>GridWorld playground!</p><p>I made <a href=https://gridworld-playground.glitch.me>a website</a> where you can</p><ul><li>Draw your own GridWorlds</li><li>Play around with hyperparameters while agent is training</li><li>Transfer values between agents</li><li>&ldquo;Teleport&rdquo; the agent to help it during learning</li></ul><p>Hope you find it useful and fun!</p><p><a href=https://gridworld-playground.glitch.me><img src=/posts/mentoring/gridworldPlayground/gridWorldPlayground.gif alt="GridWorld Playground" class=center></a></p></p></div><div class=card-footer><span class=float-left>March 16, 2020</span>
<a href=/posts/mentoring/gridworldplayground/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div></div><div class=paginator><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/posts/page/2/ aria-label=Previous class=page-link role=button><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a href=/posts/ aria-label="Page 1" class=page-link role=button>1</a></li><li class=page-item><a href=/posts/page/2/ aria-label="Page 2" class=page-link role=button>2</a></li><li class="page-item active"><a aria-current=page aria-label="Page 3" class=page-link role=button>3</a></li><li class=page-item><a href=/posts/page/4/ aria-label="Page 4" class=page-link role=button>4</a></li><li class=page-item><a href=/posts/page/4/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/posts/page/4/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div></section></div><footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=#about>About</a></li><li class=nav-item><a class=smooth-scroll href=#recent-posts>Recent Posts</a></li><li class=nav-item><a class=smooth-scroll href=#publications>Selected Publications</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><span><a href=https://twitter.com/@pcastr target=_blank>Twitter <i class="fab fa-twitter"></i></a></span></li></ul><a rel=me href=https://sigmoid.social/@psc>Mastodon</a></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=#><img src=/assets/images/inverted-logo.png>
Toha</a></div><div class="col-md-4 text-center">© 2020 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/>Powered by
<img src=/assets/images/hugo-logo-wide.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script src=/assets/js/jquery-3.4.1.min.js></script><script src=/assets/js/popper.min.js></script><script src=/assets/js/bootstrap.min.js></script><script src=/assets/js/navbar.js></script><script src=/assets/js/main.js></script><script src=/assets/js/list.js></script></body></html>
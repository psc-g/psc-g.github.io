<!doctype html><html lang=en><head><meta name=generator content="Hugo 0.77.0"><title>psc's website</title><meta name=description content="Homepage of Pablo Samuel Castro"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/assets/css/bootstrap.min.css><link rel=stylesheet href=/assets/css/layouts/main.css><link rel=stylesheet href=/assets/css/style.css><link rel=stylesheet href=/assets/css/navigators/navbar.css><link href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css><link rel=icon type=image/png href=/assets/images/psc_emoji.png><link rel=stylesheet href=/assets/css/style.css><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],processEscapes:true,processEnvironments:true},options:{skipHtmlTags:['script','noscript','style','textarea','pre']}};window.addEventListener('load',(event)=>{document.querySelectorAll("mjx-container").forEach(function(x){x.parentElement.classList+='has-jax'})});</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/assets/css/sections/home.css><link rel=stylesheet href=/assets/css/sections/about.css><link rel=stylesheet href=/assets/css/sections/skills.css><link rel=stylesheet href=/assets/css/sections/experiences.css><link rel=stylesheet href=/assets/css/sections/projects.css><link rel=stylesheet href=/assets/css/sections/recent-posts.css><link rel=stylesheet href=/assets/css/sections/achievements.css><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-XXXXXXXXX-X','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body data-spy=scroll data-target=#top-navbar data-offset=100><nav class="navbar navbar-expand-xl top-navbar initial-navbar" id=top-navbar><div class=container><a class=navbar-brand href=/><img src=/assets/images/psc_emoji.png id=logo>psc's website</a>
<button class="navbar-toggler navbar-dark" id=navbar-toggler type=button data-toggle=collapse data-target=#top-nav-items>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=top-nav-items><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=#home>Home</a></li><li class=nav-item><a class=nav-link href=#about>About</a></li><li class=nav-item><a class=nav-link href=#recent-posts>Recent Posts</a></li><li class=nav-item><a class=nav-link href=#publications>Publications</a></li><div class=dropdown-divider id=top-navbar-divider></div><li class=nav-item><a class=nav-link id=blog-link href=/posts>Posts</a></li></ul></div></div><img src=/assets/images/psc_emoji.png class=d-none id=main-logo>
<img src=/assets/images/psc_emoji.png class=d-none id=inverted-logo></nav><div class="container-fluid home" id=home><div class="background container-fluid" style=background-image:url(https://psc-g.github.io/assets/images/background.jpg)></div><div class="container content text-center"><img src=/assets/images/psc_gradient.png class="rounded-circle mx-auto d-block img-fluid"><h1 class=greeting>Hola, I'm psc</h1><div class=typing-carousel><span id=ityped class=ityped></span><span class=ityped-cursor></span></div><ul id=typing-carousel-data><li>Researcher</li><li>Developer</li><li>Musician</li></ul><a href=#about><i class="arrow bounce fa fa-chevron-down"></i></a></div></div><div class="container-fluid section-holder d-flex bg-white"><div class="container anchor p-lg-5 about-section" id=about><div class="row pt-sm-2 pt-md-4 align-self-center"><h3 class=p-1>Pablo Samuel Castro</h3><h5 class=p-1>Señor Swesearcher
at <a href=https://ai.google/>Google</a></h5><p class="p-1 text-justify">I was born and raised in Quito, Ecuador, and moved to Montreal after high school to study at McGill. I stayed in Montreal for the next 10 years, finished my bachelors, worked at a flight simulator company, and then eventually obtained my masters and PhD at McGill, focusing on Reinforcement Learning under the supervision of Doina Precup and Prakash Panangaden. After my PhD I did a 10-month postdoc in Paris before moving to Pittsburgh to join Google. I have worked at Google for close to 9 years, and am currently a staff research Software Developer in Google Brain in Montreal, focusing on fundamental Reinforcement Learning research, Machine Learning and Creativity, and being a regular advocate for increasing the LatinX representation in the research community. Aside from my interest in coding/AI/math, I am an <a href=https://www.psctrio.com/>active musician</a>, love running (6 marathons so far, including Boston!), and discussing politics and activism.</p><div class="text-container ml-auto"><ul class="social-link d-flex"><li><a href=https://twitter.com/pcastr target=/><i class="fab fa-twitter"></i></a></li><li><a href=https://github.com/psc-g target=/><i class="fab fa-github"></i></a></li></ul></div></div></div></div><div class="container-fluid section-holder d-flex bg-dimmed"><div class="container-fluid anchor pb-5 recent-posts-section" id=recent-posts><h1 class=text-center>Recent Posts</h1><div class=container><div class=row id=recent-post-cards><div class="col-lg-4 col-md-6 pt-2 post-card"><a href=/posts/research/rl/revisiting_rainbow/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/research/rl/revisiting_rainbow/revisiting_rainbow.png alt="Card image cap"></div><div class=card-body><h5 class=card-title>Revisiting Rainbow: Promoting more insightful and inclusive deep reinforcement learning research</h5><p class="card-text post-summary">Johan S. Obando-Ceron and Pablo Samuel Castro
This is a summary of our paper which will be presented in the deep reinforcement learning workshop at NeurIPS 2020.
Introduction Since the introduction of DQN Mnih et al., 2015 reinforcement learning has witnessed a dramatic increase in research papers Henderson et al., 2018. A large portion of these papers propose new methods that build on the original DQN algorithm and network architecture, often adapting methods introduced before DQN to work well with deep networks.</p></div><div class=card-footer><span class=float-left>November 26, 2020</span>
<a href=/posts/research/rl/revisiting_rainbow/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class="col-lg-4 col-md-6 pt-2 post-card"><a href=/posts/research/creativity/ganterpretations/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/research/creativity/ganterpretations/gandy.gif alt="Card image cap"></div><div class=card-body><h5 class=card-title>GANterpretations</h5><p class="card-text post-summary">GANterpretations is an idea I published in this paper, which was accepted to the 4th Workshop on Machine Learning for Creativity and Design at NeurIPS 2020. The code is available here.
At a high level what it does is use the spectrogram of a piece of audio (from a video, for example) to &ldquo;draw&rdquo; a path in the latent space of a BigGAN.
The following video walks through the process:</p></div><div class=card-footer><span class=float-left>November 8, 2020</span>
<a href=/posts/research/creativity/ganterpretations/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class="col-lg-4 col-md-6 pt-2 post-card"><a href=/posts/mentoring/intro-to-rl/intro-to-rl/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/posts/mentoring/intro-to-rl/cartpole.gif alt="Card image cap"></div><div class=card-body><h5 class=card-title>Introduction to reinforcement learning</h5><p class="card-text post-summary">This post is based on this colab.
You can also watch a video where I go through the basics here.
Pueden ver un video (en español) donde presento el material aquí.
Introduction Reinforcement learning methods are used for sequential decision making in uncertain environments. It is typically framed as an agent (the learner) interacting with an environment which provides the agent with reinforcement (positive or negative), based on the agent&rsquo;s decisions.</p></div><div class=card-footer><span class=float-left>October 14, 2020</span>
<a href=/posts/mentoring/intro-to-rl/intro-to-rl/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-white"><div class="container-fluid anchor pb-5 publications-section" id=publications><h1 class=text-center>Publications</h1><div class="container ml-auto text-center"><div class="btn-group flex-wrap" role=group id=publication-filter-buttons><button type=button class="btn btn-dark" data-filter=all>
All</button>
<button type=button class="btn btn-dark" data-filter=rl>
Reinforcement Learning</button>
<button type=button class="btn btn-dark" data-filter=creativity>
Creativity</button>
<button type=button class="btn btn-dark" data-filter=ml>
General Machine Learning</button>
<button type=button class="btn btn-dark" data-filter=2020>
2020</button>
<button type=button class="btn btn-dark" data-filter=2019>
2019</button>
<button type=button class="btn btn-dark" data-filter=2018>
2018</button></div></div><div class="container filtr-projects"><div class=row id=project-card-holder><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category="all, rl,2020"><div class="card mt-1"><div class=card><a class=card-header href=/posts/research/rl/scalable><div><div class=d-flex><h5 class="card-title mb-0">Scalable methods for computing state similarity in deterministic markov decision processes</h5></div><div class=sub-title><span>Pablo Samuel Castro</span>
<span>AAAI, 2020</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://github.com/google-research/google-research/tree/master/bisimulation_aaai2020 target=_blank>GitHub</a></span>
<span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=http://arxiv.org/abs/1911.09291 target=_blank>Paper</a></span>
<span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=/posts/research/rl/scalable>Blog post</a></span></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category="all, rl,2018"><div class="card mt-1"><div class=card><a class=card-header href=/posts/research/rl/dopamine><div><div class=d-flex><h5 class="card-title mb-0">Dopamine, A Research Framework for Deep Reinforcement Learning</h5></div><div class=sub-title><span>Pablo Samuel Castro, Subhodeep Moitra, Carles Gelada, Saurabh Kumar, and Marc G. Bellemare</span>
<span>Preprint, 2018</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://github.com/google/dopamine target=_blank>GitHub</a></span>
<span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://arxiv.org/abs/1812.06110 target=_blank>Paper</a></span>
<span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=/posts/research/rl/dopamine>Blog post</a></span></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category="all, creativity,2020"><div class="card mt-1"><div class=card><a class=card-header href=/posts/research/creativity/ganterpretations><div><div class=d-flex><h5 class="card-title mb-0">GANterpretations</h5></div><div class=sub-title><span>Pablo Samuel Castro</span>
<span>Machine Learning for Creativity and Design workshop at NeurIPS, 2020</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://github.com/psc-g/ganterpretation target=_blank>GitHub</a></span>
<span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=/posts/research/creativity/ganterpretations>Blog post</a></span></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category="all, ml,2020"><div class="card mt-1"><div class=card><a class=card-header href=/posts/research/other/rigl><div><div class=d-flex><h5 class="card-title mb-0">Rigging the lottery, Making all tickets winners</h5></div><div class=sub-title><span>Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, and Erich Elsen</span>
<span>ICML, 2020</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://github.com/google-research/rigl target=_blank>GitHub</a></span>
<span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://arxiv.org/abs/1911.11134 target=_blank>Paper</a></span>
<span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=/posts/research/other/rigl>Blog post</a></span></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category="all, rl,2019"><div class="card mt-1"><div class=card><a class=card-header href=https://proceedings.neurips.cc/paper/2019/hash/3cf2559725a9fdfa602ec8c887440f32-Abstract.html><div><div class=d-flex><h5 class="card-title mb-0">A Geometric Perspective on Optimal Representations for Reinforcement Learning</h5></div><div class=sub-title><span>Marc G. Bellemare, Will Dabney, Robert Dadashi, Adrien Ali Taiga, Pablo Samuel Castro, Nicolas Le Roux, Dale Schuurmans, Tor Lattimore, and Clare Lyle</span>
<span>NeurIPS, 2019</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://proceedings.neurips.cc/paper/2019/hash/3cf2559725a9fdfa602ec8c887440f32-Abstract.html target=_blank>Paper</a></span></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category="all, rl,2019"><div class="card mt-1"><div class=card><a class=card-header href=https://www.aaai.org/ojs/index.php/AAAI/article/view/4365><div><div class=d-flex><h5 class="card-title mb-0">A comparative analysis of expected and distributional reinforcement learning</h5></div><div class=sub-title><span>Clare Lyle, Pablo Samuel Castro, and Marc G. Bellemare</span>
<span>AAAI, 2019</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://www.aaai.org/ojs/index.php/AAAI/article/view/4365 target=_blank>Paper</a></span></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category="all, creativity,2019"><div class="card mt-1"><div class=card><a class=card-header href=/posts/research/creativity/ml-jam><div><div class=d-flex><h5 class="card-title mb-0">ML-Jam, Performing Structured Improvisations with Pre-trained Models</h5></div><div class=sub-title><span>Pablo Samuel Castro</span>
<span>ICCC, 2019</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://github.com/psc-g/Psc2 target=_blank>GitHub</a></span>
<span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://arxiv.org/abs/1904.13285 target=_blank>Paper</a></span>
<span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=/posts/research/creativity/ml-jam>Blog post</a></span></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category="all, creativity,2020"><div class="card mt-1"><div class=card><a class=card-header href=https://arxiv.org/abs/1901.11528><div><div class=d-flex><h5 class="card-title mb-0">Shaping the Narrative Arc, Information-Theoretic Collaborative Dialogue</h5></div><div class=sub-title><span>Kory Mathewson, Pablo Samuel Castro, Colin Cherry, George Foster, and Marc G. Bellemare</span>
<span>ICCC, 2020</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://arxiv.org/abs/1901.11528 target=_blank>Paper</a></span></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category="all, rl,2019"><div class="card mt-1"><div class=card><a class=card-header href=https://arxiv.org/abs/1812.07069><div><div class=d-flex><h5 class="card-title mb-0">An Atari Model Zoo for Analyzing, Visualizing, and Comparing Deep Reinforcement Learning Agents</h5></div><div class=sub-title><span>Felipe Petroski Such, Vashisht Madhavan, Rosanne Liu, Rui Wang, Pablo Samuel Castro, Yulun Li, Jiale Zhi, Ludwig Schubert, Marc G. Bellemare, Jeff Clune, and Joel Lehman</span>
<span>IJCAI, 2019</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://github.com/uber-research/atari-model-zoo target=_blank>GitHub</a></span>
<span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://arxiv.org/abs/1812.07069 target=_blank>Paper</a></span></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category="all, rl,2019"><div class="card mt-1"><div class=card><a class=card-header href=https://arxiv.org/abs/1902.03149><div><div class=d-flex><h5 class="card-title mb-0">Distributional reinforcement learning with linear function approximation</h5></div><div class=sub-title><span>Marc G. Bellemare, Nicolas Le Roux, Pablo Samuel Castro, and Subhodeep Moitra</span>
<span>AISTATS, 2019</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://arxiv.org/abs/1902.03149 target=_blank>Paper</a></span></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category="all, rl,2019"><div class="card mt-1"><div class=card><a class=card-header href=https://arxiv.org/abs/1907.13411><div><div class=d-flex><h5 class="card-title mb-0">Inverse reinforcement learning with multiple ranked experts</h5></div><div class=sub-title><span>Pablo Samuel Castro, Shijian Li, and Daqing Zhang</span>
<span>Preprint, 2019</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><span class=float-right><a class="btn btn-outline-info btn-sm mb-2" href=https://arxiv.org/abs/1907.13411 target=_blank>Paper</a></span></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category="all, pre-2018"><div class="card mt-1"><div class=card><a class=card-header href=#><div><div class=d-flex><h5 class="card-title mb-0">Pre-2018 work</h5></div><div class=sub-title><span>Multiple authors</span>
<span>Pre-2018</span></div></div></a><div class="card-body text-justify pt-1 pb-1"></div></div></div></div></div></div><hr><div class="container ml-auto text-center">All prior publications can be found on my <a href="https://scholar.google.com/citations?user=jn5r6TsAAAAJ&hl=en" target=_blank>Google Scholar Page</a>.</div></div></div><footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=#about>About</a></li><li class=nav-item><a class=smooth-scroll href=#recent-posts>Recent Posts</a></li><li class=nav-item><a class=smooth-scroll href=#publications>Publications</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><span><a href=https://twitter.com/@pcastr target=_blank>Twitter <i class="fab fa-twitter"></i></a></span></li></ul></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=#><img src=/assets/images/inverted-logo.png>
Toha</a></div><div class="col-md-4 text-center">© 2020 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/>Powered by
<img src=/assets/images/hugo-logo-wide.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script src=/assets/js/jquery-3.4.1.min.js></script><script src=/assets/js/popper.min.js></script><script src=/assets/js/bootstrap.min.js></script><script src=/assets/js/navbar.js></script><script src=/assets/js/main.js></script><script src=/assets/js/itype.min.js></script><script src=/assets/js/github-button.js></script><script src=/assets/js/home.js></script><script src=/assets/js/jquery.filterizr.min.js></script></body></html>